{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\WORK\\projects\\machine_learing\\Dogs and Cats\\Dataset\\PetImages\\Dog\n",
      "E:\\WORK\\projects\\machine_learing\\Dogs and Cats\\Dataset\\PetImages\\Cat\n"
     ]
    }
   ],
   "source": [
    "DIRECTORY = \"E:\\WORK\\projects\\machine_learing\\Dogs and Cats\\Dataset\\PetImages\"\n",
    "categories = ['Dog','Cat']\n",
    "IMG_SIZE = 50\n",
    "train_list = []\n",
    "for category in categories:\n",
    "    DATASET_DIR = os.path.join(DIRECTORY,category)\n",
    "    print(DATASET_DIR)\n",
    "    all_images = os.listdir(DATASET_DIR)\n",
    "    for image in all_images:\n",
    "        img_arr = cv2.imread(os.path.join(DATASET_DIR,image),cv2.IMREAD_GRAYSCALE)\n",
    "        try:\n",
    "            img_arr_compressed = cv2.resize(img_arr,(IMG_SIZE,IMG_SIZE))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        train_list.append([img_arr_compressed,categories.index(category)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_list)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in train_list:\n",
    "    X_train.append(i[0])\n",
    "    Y_train.append(i[1])\n",
    "# print(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17501 samples, validate on 7501 samples\n",
      "Epoch 1/3\n",
      "17501/17501 [==============================] - 851s 49ms/sample - loss: 0.6553 - accuracy: 0.6198 - val_loss: 0.6040 - val_accuracy: 0.6776\n",
      "Epoch 2/3\n",
      "17501/17501 [==============================] - 843s 48ms/sample - loss: 0.5869 - accuracy: 0.6902 - val_loss: 0.5593 - val_accuracy: 0.7170\n",
      "Epoch 3/3\n",
      "17501/17501 [==============================] - 871s 50ms/sample - loss: 0.5468 - accuracy: 0.7276 - val_loss: 0.5220 - val_accuracy: 0.7452\n",
      "WARNING:tensorflow:From C:\\Users\\acer\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: 64x3-CNN.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=3, validation_split=0.3)\n",
    "model.save('64x3-CNN.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
    "    img_array = img_array/255.0\n",
    "    new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE),1)\n",
    "    return new_array.reshape(-1,IMG_SIZE,IMG_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"64x3-CNN.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55430305]]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('dog.jpg')])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "categories = [\"Dog\",\"Cat\"]\n",
    "print(categories[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
